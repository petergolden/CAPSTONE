{
    "contents" : "# Add Libraries\nlibrary(ROCR)\nlibrary(caret)\nlibrary(neuralnet)\nlibrary(party) # for KT's Random Forest syntax\n\n# Load orders.train post imputation and transformations\nload(\"~/CAPSTONE/imputedOrdersPostTransformation.rdata\")\n\n# Models and ML Algorithms\n\nsummary(orders.train)\nload(\"imputedOrdersPostTransformation.rdata\")\n#------------------------#\n#  Train & Test Split    #\n#------------------------#\n\n# Train/Test split (doing 70/30, based on number of orders)\n# Just writing out syntax here- probably makes more sense to put it after the EDA, though.\n# There's probably a more elegant way to do this but I just went with syntax I already know. Feel free to update.\nsmp_size <- floor(0.7 * max(orders.train$orderID))\nset.seed(498)\ntrain_ind <- sample(seq_len(max(orders.train$orderID)), size = smp_size)\norders.train$trainTest <- train_ind[orders.train$orderID]\ntrain <- orders.train[which(orders.train$trainTest>0), ]\ntest <- orders.train[-which(orders.train$trainTest>0), ]\nremove(smp_size,train_ind)\n\n#------END TRAIN/TEST SPLIT-------#\n\nremove(orders.train) # To clean workspace for 'hungry' algorithms\n\n#----------------------#\n#  Logistic Regression #\n#----------------------#\n# Look at Week 3 assignment of Predict 412\n\nstr(train)\ntrain$creationDate\n\ntrain$numItemsInOrder\ntrain$numItemID\n\n#------ LR \"Specified Model\"----------#\nreturns.lr <- glm(returnShipment ~ color + timeToDeliver \n                  + salutation + state\n                  + accountAge + customerAge \n                  + holidayFlag + bdayFlag \n                  + LetterSize + Pants + ChildSize + ShoeDress \n                  + difFromMeanPrice + price  \n                  + numCustOrders + numCustReturns + custRiskFlag \n                  + numItemReturns + numItemOrders + itemRiskFlag\n                  + numManufOrders + numManufReturns + manufRiskFlag,\n              family=binomial(link=logit), data=train)\nsummary(returns.lr)\n\n# TO Get ROC Curves\n# get predictions from model \n# NEED TO KNOW WHAT WE CALL TRAIN AND TEST DATA SETS\npredict.train.logistic <- predict(returns.lr, train, type=\"response\")\npredict.test.logistic <- predict(returns.lr, test, type=\"response\")\n\ntrain.logistic.pred <- prediction(predict.train.logistic, train$returnShipment)\ntrain.logistic.roc <- performance(train.logistic.pred, \"tpr\",\"fpr\")\ntrain.logistic.auc <- (performance(train.logistic.pred, \"auc\"))@y.values\n\ntest.logistic.pred <- prediction(predict.test.logistic, test$returnShipment)\ntest.logistic.roc <- performance(test.logistic.pred, \"tpr\",\"fpr\")\ntest.logistic.auc <- (performance(test.logistic.pred, \"auc\"))@y.values\n\n# plot the model ROC curves\npdf(file = \"LR_model_ROC.pdf\", width = 11, height = 8.5)  ##/\\open pdf/\\##\n\nplot(train.logistic.roc, col = \"darkgreen\", main = \"ROC Curves for Logistic Regression Model\")\nplot(test.logistic.roc, col = \"red\",  add = TRUE)\nabline(c(0,1))\n# Draw a legend.\ntrain.legend <- paste(\"Train: AUC=\", round(train.logistic.auc[[1]], digits=3))\ntest.legend <- paste(\"Test : AUC=\", round(test.logistic.auc[[1]], digits=3))\nlegend(0.6, 0.5, c(train.legend,test.legend), c(3,2))\ndev.off()\n\nstr(predict.test.logistic) \n\n\n# ----------------LR \"Full Model\" ----------------------------#\n# Had to add variables manually as I was getting an error just using returnShipment~.\n# Also realized some variables, particularly date vaiables and ID number variables (in number format)\n# did not really behave like continuous variables\n# or variables where value on a continuum was meaningful\n# Didn't want spurious results so eliminated those first\n# careful here - full model sucks resources\n# I think there are multicollinearity issues here\n# Let's see how BE goes, but we might need to do some manual manipulation \n# CustomerAge has some NA's - need to check impute for this variable\nreturns.full.lr <- glm(returnShipment ~ color + timeToDeliver \n                  + salutation + state\n                  + accountAge \n                  + holidayFlag + bdayFlag \n                  + LetterSize + Pants + ChildSize + ShoeDress + sizeHighRisk + sizeLowRisk\n                  + difFromMeanPrice + price  \n                  + numItemsInOrder\n                  + numCustOrders + numCustReturns + custRiskFlag \n                  + numItemReturns + numItemOrders + itemRiskFlag\n                  + numManufOrders + numManufReturns + manufRiskFlag,\n                  family=binomial(link=logit), data=train)\nsummary(returns.full.lr)\n\n# generate ROC on FULL MODEL\npredict.train.logistic <- predict(returns.full.lr, train, type=\"response\")\npredict.test.logistic <- predict(returns.full.lr, test, type=\"response\")\n\ntrain.logistic.pred <- prediction(predict.train.logistic, train$returnShipment)\ntrain.logistic.roc <- performance(train.logistic.pred, \"tpr\",\"fpr\")\ntrain.logistic.auc <- (performance(train.logistic.pred, \"auc\"))@y.values\n\ntest.logistic.pred <- prediction(predict.test.logistic, test$returnShipment)\ntest.logistic.roc <- performance(test.logistic.pred, \"tpr\",\"fpr\")\ntest.logistic.auc <- (performance(test.logistic.pred, \"auc\"))@y.values\n\n# plot the full model ROC curves\npdf(file = \"LR_model_Full_ROC.pdf\", width = 11, height = 8.5)  ##/\\open pdf/\\##\n\nplot(train.logistic.roc, col = \"darkgreen\", main = \"ROC Curves for Logistic Regression Model\")\nplot(test.logistic.roc, col = \"red\",  add = TRUE)\nabline(c(0,1))\n# Draw a legend.\ntrain.legend <- paste(\"Train: AUC=\", round(train.logistic.auc[[1]], digits=3))\ntest.legend <- paste(\"Test : AUC=\", round(test.logistic.auc[[1]], digits=3))\nlegend(0.6, 0.5, c(train.legend,test.legend), c(3,2))\ndev.off()\n\n\n#---------- Backwards elimination selection-----------#\n# use default AIC measure\n# Note step function uses full model defined above \nreturns.backward.lr <- step(returns.full.lr)\nsummary(returns.backward.lr)\n\n\n# TO Get ROC Curves\n# get predictions from model \npredict.train.logistic <- predict(returns.backward.lr, train, type=\"response\")\npredict.test.logistic <- predict(returns.backward.lr, test, type=\"response\")\n\ntrain.logistic.pred <- prediction(predict.train.logistic, train$returnShipment)\ntrain.logistic.roc <- performance(train.logistic.pred, \"tpr\",\"fpr\")\ntrain.logistic.auc <- (performance(train.logistic.pred, \"auc\"))@y.values\n\ntest.logistic.pred <- prediction(predict.test.logistic, test$returnShipment)\ntest.logistic.roc <- performance(test.logistic.pred, \"tpr\",\"fpr\")\ntest.logistic.auc <- (performance(test.logistic.pred, \"auc\"))@y.values\n\n# plot the model ROC curves\npdf(file = \"LR_model_backward_elim_ROC.pdf\", width = 11, height = 8.5)  ##/\\open pdf/\\##\n\nplot(train.logistic.roc, col = \"darkgreen\", main = \"ROC Curves for Logistic Regression Model\")\nplot(test.logistic.roc, col = \"red\",  add = TRUE)\nabline(c(0,1))\n# Draw a legend.\ntrain.legend <- paste(\"Train: AUC=\", round(train.logistic.auc[[1]], digits=3))\ntest.legend <- paste(\"Test : AUC=\", round(test.logistic.auc[[1]], digits=3))\nlegend(0.6, 0.5, c(train.legend,test.legend), c(3,2))\ndev.off()\n\nstr(predict.test.logistic) \n\n#--Backwards Elimination Model----#\n\nglm(formula = returnShipment ~ color + timeToDeliver + salutation + \n      accountAge + holidayFlag + LetterSize + ChildSize + ShoeDress + \n      sizeHighRisk + sizeLowRisk + difFromMeanPrice + price + numItemsInOrder + \n      numCustOrders + numCustReturns + custRiskFlag + numItemReturns + \n      numItemOrders + numManufOrders, family = binomial(link = logit), \n    data = train)\n\n#------------------#\n# Confusion Matrix #  \n#------------------#\n# We need to convert preds to actual choice; introduce 'cut'\n# selected a p=.4 cutoff after review of ROC\npredictions<-cut(predict.test.logistic, c(-Inf,0.4,Inf), labels=c(\"Keep\",\"Return\"))\n# Now have a look - classes are assigned\nstr(predictions)\nsummary(predictions)\n# compare to test$pick to ensure same # of levels and obs\n# Need to impute or eliminate observations with NAs or else have above issue\nstr(test$returnShipment)\nsummary(test$returnShipment)\n\nconfusionMatrix(predictions, test$returnShipment)\n\nstr(predictions)\nstr(test$returnShipment)\n\n#clean workspace for next algorithm (KT- leave test.logistic.roc/test.logistic.pred for final comparison)\nremove(predict.test.logistic, predict.train.logistic, predictions, returns.lr, \n       test.logistic.auc, #test.logistic.pred, test.logistic.roc,\n       train.logistic.roc, train.logistic.pred, train.logistic.auc,\n       test.legend,train.legend)\n\n#------------------#\n#  Decision Trees  #\n#------------------#\n# J48 (based on Quinlan's C4.5)\nlibrary(RWeka)\n# to run j48 in RWeka\n# Careful this takes a few minutes!\nremove(orders.train) # clean space\n# J48 cannot handle numeric class - have to convert to factor\nRS <- as.factor(train$returnShipment)\nreturns_j48 <- J48(RS ~ color + timeToDeliver \n                   + salutation + state\n                   + accountAge + customerAge \n                   + holidayFlag + bdayFlag \n                   + LetterSize + Pants + ChildSize + ShoeDress \n                   + difFromMeanPrice + price  \n                   + numCustOrders + numCustReturns + custRiskFlag \n                   + numItemReturns + numItemOrders + itemRiskFlag\n                   + numManufOrders + numManufReturns + manufRiskFlag,\n                   data=train)\nreturns_j48\nsummary(returns_j48)\n\n# WILL ROC WORK FOR J48? Do we need to use type='class' or 'probability'?\n# Keep getting error ' Format of labels is invalid.'\npredict.train.J48 <- predict(returns_j48, train, type=\"probability\")\npredict.test.J48 <- predict(returns_j48, test, type=\"probability\")\n\ntrain.J48.pred <- prediction(predict.train.J48, train$RS)\ntrain.J48.roc <- performance(train.J48.pred, \"tpr\",\"fpr\")\ntrain.J48.auc <- (performance(train.J48.pred, \"auc\"))@y.values\n\ntest.J48.pred <- prediction(predict.test.J48, test$RS)\ntest.J48.roc <- performance(test.J48.pred, \"tpr\",\"fpr\")\ntest.J48.auc <- (performance(test.J48.pred, \"auc\"))@y.values\n\n# plot the selected model ROC curves\npdf(file = \"J48_model_ROC.pdf\", width = 11, height = 8.5)  ##/\\open pdf/\\##\n\nplot(train.J48.roc, col = \"darkgreen\", main = \"ROC Curves for Logistic Regression Model\")\nplot(test.J48.roc, col = \"red\",  add = TRUE)\nabline(c(0,1))\n# Draw a legend.\ntrain.legend <- paste(\"Train: AUC=\", round(train.J48.auc[[1]], digits=3))\ntest.legend <- paste(\"Test : AUC=\", round(test.J48.auc[[1]], digits=3))\nlegend(0.6, 0.5, c(train.legend,test.legend), c(3,2))\ndev.off()\n\n# to add a 10-folds cross-validation (does it help?)\neval_j48 <- evaluate_Weka_classifier(returns_j48, numFolds = 10, complexity = FALSE, \n                                     seed = 1, class = TRUE)\neval_j48\n\n#--------------------#\n#   Random Forests   #\n#--------------------#\n# KT - Code from 412 week 5, need to update to current dataset\n# References for this section: \n# http://www.stanford.edu/~stephsus/R-randomforest-guide.pdf\n# http://heuristically.wordpress.com/2009/12/18/plot-roc-curve-lift-chart-random-forest/\n\nset.seed(498)\npdf(\"RandomForestPlots.pdf\")\n\n# The code crashed RStudio on me- trying with a much smaller sample to see if the syntax itself works\nsample_ind <- sample(seq_len(nrow(train)), size = 1000)\ntrain.sample <- train [sample_ind, ]\n\n# fit a random forest model to smaller training set\ndata.controls <- cforest_unbiased(ntree=1000, mtry=5) #ntree should be increased from default of 500 based on number of predictors and datapoints, mtry default is 5, suggested is sqrt of predictors\ncforest.model <- cforest(returnShipment ~ color + timeToDeliver \n                         + salutation + state\n                         + accountAge + customerAge \n                         + holidayFlag + bdayFlag \n                         + LetterSize + Pants + ChildSize + ShoeDress \n                         + difFromMeanPrice + price  \n                         + numCustOrders + numCustReturns + custRiskFlag \n                         + numItemReturns + numItemOrders + itemRiskFlag\n                         + numManufOrders + numManufReturns + manufRiskFlag\n                         , data = train.sample, controls=data.controls) \n\n# Variable importance - note this can also be done using randomForest as the library, but produces a dot plot\ndata.cforest.varimp <- varimp(cforest.model)\nbarplot(sort(data.cforest.varimp), horiz=T, xlab=\"Variable Importance in Training (vars to the rt of dotted line are sig)\",las=1,cex.names=0.5)\nabline(v=mean(data.cforest.varimp), col=\"red\",lty=\"longdash\", lwd=2)\nabline(v=median(data.cforest.varimp), col=\"blue\", lwd=2)\nabline(v=abs(min(data.cforest.varimp)),col=\"black\",lty=\"dotted\",lwd=2)\nlegend(\"bottomright\",c(\"Mean\",\"Median\",\"| Min |\"),lty=c(\"longdash\",\"solid\",\"dotted\"),col=c(\"red\",\"blue\",\"black\"),lwd=c(2,2,2))\n# based on sample & settings, most important vars are itemRisk, numItems, and manufRisk\n# the model doesn't appear stable though- the rest of the variables move around in importance\n\n# Use the model to predict.\npredict.forest.sample <- predict(cforest.model)\n#predict.forest.train <- predict(cforest.model)\npredict.forest.test <- predict(cforest.model, newdata = test)\n\n# Borrowed CM syntax from LR above\nRFpredictions<-cut(predict.forest.sample, c(-Inf,0.5,Inf), labels=c(\"Keep\",\"Return\"))\nstr(RFpredictions)\nsummary(RFpredictions)\nRFactuals <- factor(train.sample$returnShipment,\n                    levels = c(0,1),\n                    labels = c(\"Keep\", \"Return\"))\nconfusionMatrix(RFpredictions,RFactuals)\n\n# Plot the performance of the model applied to the evaluation set as an ROC curve.\ndetach(\"package:neuralnet\", unload=TRUE) # the prediction function of ROCR was getting overwritten\nsample.rocforest.prediction <- prediction(predict.forest.sample, train.sample[['returnShipment']])\n#train.rocforest.prediction <- prediction(predict.forest.train, train$returnShipment)\ntest.rocforest.prediction <- prediction(predict.forest.test, test$returnShipment)\n\nsample.rocforest <- performance(sample.rocforest.prediction, \"tpr\",\"fpr\")\n#train.rocforest <- performance(train.rocforest.prediction, \"tpr\",\"fpr\")\ntest.rocforest <- performance(test.rocforest.prediction, \"tpr\",\"fpr\")\n\nplot(sample.rocforest, col=\"green\", main = \"ROC Random Forest\")\n#plot(train.rocforest, col=\"blue\", main = \"ROC Random Forest\")\nplot(test.rocforest, col=\"red\", add = TRUE)\nabline(c(0,1))\nlegend(\"bottomright\",c(paste(\"Sample: AUC =\"\n        ,round(as.numeric(performance(sample.rocforest.prediction,\"auc\")@y.values),4))\n        ,paste(\"Test: AUC =\"\n        ,round(as.numeric(performance(test.rocforest.prediction,\"auc\")@y.values),4)))\n        ,fill=(c(\"green\",\"red\")))\n#legend(\"bottomright\",c(paste(\"Training: AUC =\",round(as.numeric(performance(train.rocforest.prediction,\"auc\")@y.values),4)),paste(\"Test: AUC =\",round(as.numeric(performance(test.rocforest.prediction,\"auc\")@y.values),4))),fill=(c(\"blue\",\"red\")))\n\n# And then a lift chart\nsample.liftforest <- performance(sample.rocforest.prediction, \"lift\",\"rpp\")\n#train.liftforest <- performance(train.rocforest.prediction, \"lift\",\"rpp\")\ntest.liftforest <- performance(test.rocforest.prediction, \"lift\",\"rpp\")\nplot(sample.liftforest, col=\"green\", main = \"Lift Curve Random Forest\")\n#plot(train.liftforest, col=\"blue\", main = \"Lift Curve Random Forest\")\nplot(test.liftforest, col=\"red\", add = TRUE)\nlegend(\"bottomleft\",c(\"Sample\",\"Test\"),fill=(c(\"green\",\"red\")))\n#legend(\"bottomleft\",c(\"Training\",\"Test\"),fill=(c(\"blue\",\"red\")))\ndev.off()\n\n#clean up everything other than the model itself & test.rocforest/test.rocforest.prediction\nremove(predict.forest.sample,predict.forest.test,data.cforest.varimp,data.controls,sample.liftforest,sample.rocforest\n       ,sample.rocforest.prediction,sample_ind,test.liftforest)\n\n# reload the neuralnet package so it's available for later syntax\nlibrary(neuralnet)\n\n#-----------------------------#\n#   Support Vector Machines   #\n#-----------------------------#\nlibrary(e1071)  \t#for Support Vector Machines\n\n\n#------PLACE HOLDER FROM 412 CODE------------#\n\n# Whoa there!  This one killed my PC! (JB)  \n# Not sure if that's b/c of the NA's or if it's an expensive computational method\n\n\nsvmmodel <- svm(returnShipment ~ color + timeToDeliver + accountAge \n                + customerAge + holidayFlag + bdayFlag + numItemsInOrder\n                + manufRiskFlag + itemRiskFlag\n                , data = train)\nprint(svmmodel)\nsummary(svmmodel)\n\nsvmprediction <- predict(svmmodel, test)\nconfusionMatrix(svmprediction, test$returnShipment)\nca <- table(svmprediction, test$returnShipment)\nclassAgreement(ca)\n\n# optimize C and Gamma\ntobj <- tune.svm(returnShipment ~ color + timeToDeliver + accountAge \n                 + customerAge + holidayFlag + bdayFlag + numItemsInOrder\n                 + manufRiskFlag + itemRiskFlag\n                 , data = train, \n                 gamma = 10^(-6:-3), cost = 10^(1:2))\nsummary(tobj)\n\n#plot error landscape\npdf(file = \"SVM_error_landscape.pdf\", width = 11, height = 8.5)\t##/\\open pdf/\\##\nplot(tobj, transform.x = log10, xlab = expression(log[10](gamma)),\n     ylab = \"C\")\ndev.off()\t\t\t\t\t\t\t\t\t\t##\\/close pdf\\/##\n\n\n# use optimized  C and gamma\nbestGamma <- tobj$best.parameters[[1]]\nbestC <- tobj$best.parameters[[2]]\nnewsvmmodel <- svm(returnShipment ~ ., data = train,\n                   cost = bestC, gamma = bestGamma, cross = 10)\nsummary(newsvmmodel)\n\n# show confusion matrix\nnewsvmprediction <- predict(newsvmmodel, test)\nconfusionMatrix(newsvmprediction, test$returnShipment)\n\n# show class agreement function\nca <- table(newsvmprediction, test$returnShipment)\nclassAgreement(ca)\n\n# KT - This is my code from 412 if it helps, delete if it doesn't!\n################ SVM Model ###################\n# Reference:\n# http://heuristically.wordpress.com/2009/12/23/compare-performance-machine-learning-classifiers-r/\n\npdf(\"SVM.pdf\")\n\n# svm requires tuning\nset.seed(498)\nx.svm.tune <- tune(svm, class~., data = working.train, ranges = list(gamma = 2^(-12:1), cost = 2^(0:8)), tunecontrol = tune.control(sampling = \"fix\"))\n# display the tuning results (in text format)\nx.svm.tune\n\n# fit an SVM model to training set\n# Manually copy the cost and gamma from console messages above to parameters below.\nsvm.model <- svm(class ~ ., data = working.train, cost=256, gamma=0.0002441406, probability = TRUE)\n\n# Use the model to predict\npredict.svm.train <- predict(svm.model, working.train, probability = TRUE)\npredict.svm.test <- predict(svm.model, newdata = working.test, probability = TRUE)\n\n# Plot the performance of the model applied to the evaluation set as an ROC curve.\ntrain.rocsvm.prediction <- prediction(attr(predict.svm.train,\"probabilities\")[,1], working.train$class)\ntest.rocsvm.prediction <- prediction(attr(predict.svm.test, \"probabilities\")[,1], working.test$class)\ntrain.rocsvm <- performance(train.rocsvm.prediction, \"tpr\",\"fpr\")\ntest.rocsvm <- performance(test.rocsvm.prediction, \"tpr\",\"fpr\")\nplot(train.rocsvm, col=\"blue\", main = \"ROC SVM\")\nplot(test.rocsvm, col=\"red\", add = TRUE)\nabline(c(0,1))\nlegend(\"bottomright\",c(paste(\"Training: AUC =\",round(as.numeric(performance(train.rocsvm.prediction,\"auc\")@y.values),4)),paste(\"Test: AUC =\",round(as.numeric(performance(test.rocsvm.prediction,\"auc\")@y.values),4))),fill=(c(\"blue\",\"red\")))\n\n# And then a lift chart\ntrain.liftsvm <- performance(train.rocsvm.prediction, \"lift\",\"rpp\")\ntest.liftsvm <- performance(test.rocsvm.prediction, \"lift\",\"rpp\")\nplot(train.liftsvm, col=\"blue\", main = \"Lift Curve SVM\")\nplot(test.liftsvm, col=\"red\", add = TRUE)\nlegend(\"bottomleft\",c(\"Training\",\"Test\"),fill=(c(\"blue\",\"red\")))\ndev.off()\n\n#---------------------------------#\n#   Artifical Neural Networks    #\n#                                 #\n#             aka                 #\n#                                 #\n#   Associative Neural Networks   #\n#   (depending on how well I'm    #\n#   proofreading my contributions)#\n#---------------------------------#\n\nset.seed(2000)\n\n#Need to convery all our factors to quantitative inputs using dummy variables\n# R doesn't do this for you -- see http://stackoverflow.com/questions/17457028/working-with-neuralnet-in-r-for-the-first-time-get-requires-numeric-complex-ma\nsimpleDesignMatrix <- model.matrix( ~ returnShipment + timeToDeliver, \n                                    data = orders.train )\n\nnnSimple <- neuralnet(returnShipment ~ timeToDeliver,\n                   data = simpleDesignMatrix, hidden=1, threshold=0.01,\n                   linear.output = FALSE, likelihood = TRUE )\nout <- nnSimple$net.result[[1]]\nhead(out)\n#Don't need the intercept for this\nsimpleTestMatrix <- simpleDesignMatrix[,3]\n\nsimpleResults <- compute(nnSimple, simpleTestMatrix)\nsimplePredictions <- predict(nnSimple, simpleTestMatrix, type = \"class\")\nsummary(simpleResults$net.result)\n#Full model\n\n\n################ ANN Model ###################\n\ndesignMatrix <- model.matrix(~returnShipment + color + timeToDeliver \n                             + salutation + state\n                             + accountAge + customerAge \n                             + holidayFlag + bdayFlag \n                             + LetterSize + Pants + ChildSize + ShoeDress \n                             + difFromMeanPrice + price  \n                             + numCustOrders + numCustReturns + custRiskFlag \n                             + numItemReturns + numItemOrders + itemRiskFlag\n                             + numManufOrders + numManufReturns + manufRiskFlag,\n                             data = train)\n\ncovList = c(\"color\", \"timeToDeliver\", \"salutation\", \"state\", \"accountAge\",\n            \"customerAge\", \"holidayFlag\", \"bdayFlag\", \"LetterSize\", \"Pants\",\n            \"ChildSize\", \"ShoeDress\", \"difFromMeanPrice\", \"price\", \"numCustOrders\",\n            \"numCustReturns\", \"custRiskFlag\", \"numItemReturns\", \"numItemOrders\",\n            \"itemRiskFlag\", \"numManufOrders\", \"numManufReturns\", \"manufRiskFlag\")\n#Need to fix the column names so we can use them ase variable inputs into our formula\ncolnames(designMatrix)[19] <- \"salutationnotreported\"\ncolnames(designMatrix)[26] <- \"stateLowerSaxony\"\ncolnames(designMatrix)[27] <- \"stateMecklenburgWesternPomerania\"\ncolnames(designMatrix)[28] <- \"stateNorthRhineWestphalia\"\ncolnames(designMatrix)[29] <- \"stateRhinelandPalatinate\"\ncolnames(designMatrix)[32] <- \"stateSaxonyAnhalt\"\ncolnames(designMatrix)[33] <- \"stateSchleswigHolstein\"\n\nnnformula <- as.formula(paste(\"returnShipment ~ \", paste(colnames(designMatrix[,-1:-2]),collapse =\"+\")))\nnn <- neuralnet( nnformula, data = designMatrix[1:200000,], hidden=1, threshold=0.01,\n                linear.output = FALSE, likelihood = TRUE )\n\nsimpleResults <- compute(nn, test[, covList])\n\n# Ensemble Methods\n# Perhaps can average prediction from some of above\n\n#----------------------#\n#   Model Comparison   #\n#----------------------#\n\n# Code below is placeholder from 412 and needs to be updated\n################ All Models in one ROC (test data only) ###################\npdf(\"ModelComparison.pdf\")\nplot(test.logistic.roc, col=\"blue\", main = \"ROC Model Comparison\")\nplot(test.rocforest, col=\"red\", add = TRUE)\nplot(test.rocsvm, col=\"green\", add = TRUE)\nplot(test.rocann, col=\"grey\", add = TRUE)\nabline(c(0,1))\nlegend(\"bottomright\",c(paste(\"Logistic: AUC =\"\n    ,round(as.numeric(performance(test.logistic.pred,\"auc\")@y.values),4))\n    ,paste(\"Random Forest: AUC =\"\n    ,round(as.numeric(performance(test.rocforest.prediction,\"auc\")@y.values),4))\n    ,paste(\"SVM: AUC =\"\n    ,round(as.numeric(performance(test.rocsvm.prediction,\"auc\")@y.values),4))\n    ,paste(\"ANN: AUC =\"\n    ,round(as.numeric(performance(test.rocann.prediction,\"auc\")@y.values),4)))\n    ,fill=(c(\"blue\",\"red\",\"green\",\"grey\")))\ndev.off()\n\n################ All Models - Numeric Comparisons ###################\nR <- cor(cbind(trainTr$medvTr, fitted(bostonTr.model), fitted(bostonTr.step), predict(bostonTr.tree),predict(bostonTr10.nnet,trainTr)*(max(bostonTr$medvTr)-min(bostonTr$medvTr))*min(bostonTr$medvTr)))\nrownames(R) <- colnames(R) <- c(\"Actual Values\",\"Transformed\",\"Tr Stepwise\",\"Tr Tree\",\"Tr Network\")\nR\n\nRtest <- cor(cbind(testTr$medvTr, predict(bostonTr.model,testTr), predict(bostonTr.step,testTr), predict(bostonTr.tree,testTr),predict(bostonTr10.nnet,testTr)*(max(bostonTr$medvTr)-min(bostonTr$medvTr))*min(bostonTr$medvTr)))\nrownames(Rtest) <- colnames(Rtest) <- c(\"Actual Values\",\"Transformed\",\"Tr Stepwise\",\"Tr Tree\",\"Tr Network\")\nRtest\n\n############### All models ---- AIC / BIC ###############################\naic.lr <- AIC(returns.lr)\nbic.lr <- BIC(returns.lr)\naic.j48 <- AIC(returns_j48)\nbic.j48 <- BIC(returns_j48)\naic.rf <- AIC(cforest.model) # doesn't work for RF\nbic.rf <- BIC(cforest.model) # same\n\n\n\nrmse <- function(observed,predicted) {\n  sqrt(mean((observed-predicted)^2))\n}\nc(FullOLS<-rmse(testTr$medvTr,predict(bostonTr.model,testTr)),SubsetOLS<-rmse(testTr$medvTr,predict(bostonTr.step,testTr)),Tree<-rmse(testTr$medvTr,predict(bostonTr.tree,testTr)),NNet<-rmse(testTr$medvTr,predict(bostonTr10.nnet,testTr)*(max(bostonTr$medvTr)-min(bostonTr$medvTr))*min(bostonTr$medvTr)))",
    "created" : 1398821523659.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4087094741",
    "id" : "79410F17",
    "lastKnownWriteTime" : 1399528953,
    "path" : "~/GitHub/CAPSTONE/Modeling Code.R",
    "project_path" : "Modeling Code.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}