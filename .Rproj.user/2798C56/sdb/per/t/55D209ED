{
    "contents" : "#####################################\n# Run through the transformations code first to get the data with all computed variables\n# The rest of this code is currently just what had been in the DMC_KT syntax after removing variable stuff\n#####################################\n\n# Required libraries:\n  # cleaned up to remove the ones that didn't appear to be used in current code\n  # also moved ALL required libraries to the top here to load at once\nlibrary(beanplot)\nlibrary(doBy)\nlibrary(psych)\nlibrary(mi)\nlibrary(tseries)\nlibrary(forecast)\nlibrary(MMST)\nlibrary(ggplot2)\nlibrary(lattice) # required for the xyplot() function\nlibrary(car)\nlibrary(RWeka)\nlibrary(corrgram)\n\n\n#------------------------#\n#  Train & Test Split    #\n#------------------------#\n\n# Train/Test split (doing 70/30, based on number of orders)\n# Just writing out syntax here- probably makes more sense to put it after the EDA, though.\n# There's probably a more elegant way to do this but I just went with syntax I already know. Feel free to update.\nsmp_size <- floor(0.7 * max(orders.train$orderID))\nset.seed(498)\ntrain_ind <- sample(seq_len(max(orders.train$orderID)), size = smp_size)\norders.train$trainTest <- train_ind[orders.train$orderID]\ntrain <- orders.train[which(orders.train$trainTest>0), ]\ntest <- orders.train[-which(orders.train$trainTest>0), ]\nremove(smp_size,train_ind)\n\n#------END TRAIN/TEST SPLIT-------#\n\n\n# Look at PDF of numeric variables given reponse\n# Note that we're just using a random sample due to processing time for graphics\nset.seed(498)\nsample_ind <- sample(seq_len(nrow(orders.train)), size = 100)\norders.sample <- orders.train [sample_ind, ]\nbeanplot(customerAge ~ returnShipment, orders.sample, side = \"b\", col = list(\"yellow\", \"orange\"), border = c(\"yellow2\",\"darkorange\"), main = \"Customer Age Distribution\", ylab = \"Age in Years\", xaxt=\"n\")\nlegend(\"topleft\", bty=\"n\",c(\"Not Returned\", \"Returned\"), fill = c(\"yellow\", \"orange\"))\nbeanplot(accountAge ~ returnShipment, orders.sample, side = \"b\", col = list(\"yellow\", \"orange\"), border = c(\"yellow2\",\"darkorange\"), main = \"Account Age Distribution\", ylab = \"Age in Years\", xaxt=\"n\")\nlegend(\"topleft\", bty=\"n\",c(\"Not Returned\", \"Returned\"), fill = c(\"yellow\", \"orange\"))\nbeanplot(timeToDeliver ~ returnShipment, orders.sample, side = \"b\", col = list(\"yellow\", \"orange\"), border = c(\"yellow2\",\"darkorange\"), main = \"Delivery Time Distribution\", ylab = \"Time in Days\", xaxt=\"n\")\nlegend(\"topleft\", bty=\"n\",c(\"Not Returned\", \"Returned\"), fill = c(\"yellow\", \"orange\"))\nbeanplot(price ~ returnShipment, orders.sample, side = \"b\", col = list(\"yellow\", \"orange\"), border = c(\"yellow2\",\"darkorange\"), main = \"Price Distribution\", xaxt=\"n\")\nlegend(\"topleft\", bty=\"n\",c(\"Not Returned\", \"Returned\"), fill = c(\"yellow\", \"orange\"))\n\n# Mean & count of response given nominal vars\n# Only doing ones with few possible values- salutation & state\nsummaryBy(returnShipment ~ salutation, orders.train, FUN=c(length,mean))\nsummaryBy(returnShipment ~ state, orders.train, FUN=c(length,mean))\n\n# More EDA - a breakout of stats by returnShipment\ndescribeBy(orders.train, group=orders.train$returnShipment, mat=FALSE, type=3, digits=6)\n\n# quick X vs Y plot\nplot(orders.sample, cex=0.1)\n\n#--------------------------#\n# DEAL WITH MISSING VALUES #\n#--------------------------#\n\n# Not sure who added this section (JB?), but it's not working for me (KT)\n# It was JB.  Maybe too much data?  Pete will pick this up.\n\n# using mi package - get visual plot of missing obs\npdf(file = \"missing_obs_plots.pdf\", width = 11, height = 8.5)  ##/\\open pdf/\\##\nmissing.pattern.plot(orders.train, gray.scale = TRUE)\ndev.off()\t\t\t\t\t\t\t\t\t\t##\\/close pdf\\/##\n\n# check how many observations for each variable have missing values\nsum(is.na(orders.train$variable_names))\n\n#--------------------------#\n#      Imputation???       #\n#--------------------------#\n# need to decide on imputation method: mice?, \n\n\n\n\n\n# Time-series data - taking the mean of return aggregated by order date\n# NOTE- it's been awhile since I've done a TS analysis, so really I was just looking at the plots & packages here. It will likely need a fair bit of revisions.\navgReturnByDay <- summaryBy(returnShipment ~ orderDate, orders.train, FUN=mean)\nts.orders <- ts(avgReturnByDay$returnShipment.mean, start=c(2012,4), frequency=365)\nplot(ts.orders)\nacf(ts.orders,20)\npacf(ts.orders,20)\nlag.plot(ts.orders,9,do.lines=F)\nplot(diff(ts.orders))\nacf(diff(ts.orders),20)\npacf(diff(ts.orders),20)\nadf.test(ts.orders)\nauto.arima(ts.orders)\n\n#------------#\n# t-tests    #\n#------------#\n# We should add simple t-tests for binary explanatory variables\n# independent 2-group t-test\n# t.test(y~x) # where y is numeric and x is a binary factor\nt.test(returnShipment~holidayFlag, data=orders.train) # statistically significant\nt.test(returnShipment~bdayFlag, data=orders.train) # not statistically significant\nt.test(returnShipment~manufRiskFlag, data=orders.train) # TOTALLY statistically significant\nt.test(returnShipment~itemRiskFlag, data=orders.train) # TOTALLY statistically significant\nt.test(returnShipment~custRiskFlag, data=orders.train) # TOTALLY statistically significant\nt.test(returnShipment~LetterSize, data=orders.train) # statistically significant\nt.test(returnShipment~Pants, data=orders.train) # not statistically significant @95% c.i.\nt.test(returnShipment~ChildSize, data=orders.train) # statistically significant\nt.test(returnShipment~ShoeDress, data=orders.train) # statistically significant\n\n# Wait, can we look at continuous variables this way?\nt.test(price~returnShipment, data=orders.train) # statistically significant\n\n\n#---------------#\n# K-S-tests 'D' #\n#---------------#\n# K-S-tests for continuous explanatory variables \n# K-S test won't use variables 'as-is' - need to create vectors for each response variable\n\n# Price\npriceVector <- orders.train$price\nprice0 <- subset(priceVector, orders.train$returnShipment==0)\np0 <- sort(price0)\nprice1 <- subset(priceVector, orders.train$returnShipment==1)\np1 <- sort(price1)\nks.test(p0,p1) # statistically significant, moderate - large separation\nremove(price0, price1, priceVector, p0, p1) #clean workspace\n\n# Delivery Time\n# Testng to see if K-S function ranks for us, or if we have to do manually\nshipTime <- orders.train$timeToDeliver\nship0 <- subset(shipTime, orders.train$returnShipment==0)\nship1 <- subset(shipTime, orders.train$returnShipment==1)\nks.test(ship0,ship1) # statistically significant, minor separation\nremove(ship0, ship1, shipTime) #clean workspace\n\n# Looks like we don't have to rank vectors, ks.test does that for us - yay!\nshipTime <- orders.train$timeToDeliver\nship0 <- subset(shipTime, orders.train$returnShipment==0)\ns0 <- sort(ship0)\nship1 <- subset(shipTime, orders.train$returnShipment==1)\ns1 <- sort(ship1)\nks.test(s0,s1) # statistically significant, minor separation\nremove(ship0, ship1, shipTime, s0, s1) #clean workspace\n\n# Age of Account\nacctAge <- orders.train$accountAge\nacctAge0 <- subset(acctAge, orders.train$returnShipment==0)\nacctAge1 <- subset(acctAge, orders.train$returnShipment==1)\nks.test(acctAge0, acctAge1) # statistically significant, very little separation, though\nremove(acctAge0, acctAge1, acctAge) #clean workspace\n\n# Age of Customer\ncustAge <- orders.train$customerAge\ncustAge0 <- subset(custAge, orders.train$returnShipment==0)\ncustAge1 <- subset(custAge, orders.train$returnShipment==1)\nks.test(custAge0, custAge1) # statistically significant, minor separation\nremove(custAge0, custAge1, custAge) #clean workspace\n\n# Number of Items in that day's order - proxy for basket size\nnumItems <- orders.train$numItemsInOrder\nnumItems0 <- subset(numItems, orders.train$returnShipment==0)\nnumItems1 <- subset(numItems, orders.train$returnShipment==1)\nks.test(numItems0, numItems1) # statistically significant, moderate - large separation\nremove(numItems0, numItems1, custAge) #clean workspace\n\n# Frequency of returns for that manufacturer\nmanRet <- orders.train$numManufReturns\nmanRet0 <- subset(manRet, orders.train$returnShipment==0)\nmanRet1 <- subset(manRet, orders.train$returnShipment==1)\nks.test(manRet0, manRet1) # statistically significant, moderate - large separation\nremove(manRet0, manRet1, manRet) #clean workspace\n\n\n# Number of orders for a manufacturer\nmanOrd <- orders.train$numManufOrders\nmanOrd0 <- subset(manOrd, orders.train$returnShipment==0)\nmanOrd1 <- subset(manOrd, orders.train$returnShipment==1)\nks.test(manOrd0, manOrd1) # statistically significant, minor separation\nremove(manOrd0, manOrd1, manOrd) #clean workspace\n\n# Frequency of returns for item ordered\nitemRet <- orders.train$numItemReturns\nitemRet0 <- subset(itemRet, orders.train$returnShipment==0)\nitemRet1 <- subset(itemRet, orders.train$returnShipment==1)\nks.test(itemRet0, itemRet1) # statistically significant, VERY large separation\nremove(itemRet0, itemRet1, itemRet) #clean workspace\n\n# Number of orders for item ordered\nitemOrd <- orders.train$numItemOrders\nitemOrd0 <- subset(itemOrd, orders.train$returnShipment==0)\nitemOrd1 <- subset(itemOrd, orders.train$returnShipment==1)\nks.test(itemOrd0, itemOrd1) # statistically significant, minor - moderate separation\nremove(itemOrd0, itemOrd1, itemOrd) #clean workspace\n\n# Difference from the Mean Price for that item\nmeanDif <- orders.train$diffFromMeanPrice\nmeanDif0 <- subset(meanDif, orders.train$returnShipment==0)\nmeanDif1 <- subset(meanDif, orders.train$returnShipment==1)\nks.test(meanDif0, meanDif1) # statistically significant, minor - moderate separation\nremove(meanDif0, meanDif1, meanDif) #clean workspace\n\n# Frequency of returns for that Customer\ncustRet <- orders.train$numCustReturns\ncustRet0 <- subset(custRet, orders.train$returnShipment==0)\ncustRet1 <- subset(custRet, orders.train$returnShipment==1)\nks.test(custRet0, custRet1) # statistically significant, GARGANTUAN SEPARATION\nremove(custRet0, custRet1, custRet) #clean workspace\n\n# Number of orders for that Customer\ncustOrd <- orders.train$numCustOrders\ncustOrd0 <- subset(custOrd, orders.train$returnShipment==0)\ncustOrd1 <- subset(custOrd, orders.train$returnShipment==1)\nks.test(custOrd0, custOrd1) # statistically significant, minor separation\nremove(custOrd0, custOrd1, custOrd) #clean workspace\n\n\n#------------End KS----------------#\n\n# Plot Histograms for all variables by class\n# will need to sub in our data names #\n\npdf(file = \"hist_plots.pdf\", width = 11, height = 8.5)\nnm <- names(wine)[1:13]\nfor (i in seq(along = nm)) {\n  hist.plot <- ggplot(wine,aes(x = eval(parse(text = paste(\"wine$\", nm[i], sep=\"\"))),\n                               fill=factor(class))) + geom_histogram(alpha = 0.5)+xlab(nm[i])\n  print(hist.plot)\n}\ndev.off()\n\n#-------------------------#\n# Density Plots by class  #\n#-------------------------#\n# includes a loop with output routed to a pdf file\n# will need to sub in our data names #\npdf(file = \"my_plots.pdf\", width = 11, height = 8.5)\nnm <- names(wine)[1:13]\nfor (i in seq(along = nm)) {\n  this.plot <- ggplot(wine,aes(x = eval(parse(text = paste(\"wine$\", nm[i], sep=\"\"))),\n                               fill=factor(class))) + geom_density(alpha = 0.5)+xlab(nm[i])\n  print(this.plot)\n}\ndev.off()\n\n\n#------------------------------------#\n# To illustrate clustering by class  #\n# XY Plot by class                   #\n#------------------------------------#\n# lattice plots for key explanatory variables\n# Shows X&Y relationship by class - Can use for EDA or after algorithm returns top vars\n# But I think this may help identify interaction effects\n\n\n# this is just a template for integration #\nxyplot(Flav ~ Color | class, \n       data = wine,        \n       layout = c(6, 1),\n       aspect=1,\n       strip=function(...) strip.default(..., style=1),\n       xlab = \"Flavanoids\", \n       ylab = \"Color Intensity\")\n\n# Along same lines, we can look at scatterplots\n# The larger graphs with the overlay \n# make the relationships a bit more visible\n# this is by class\nscatterplot(Flav ~ Color | class, data=wine, boxplots=FALSE, \n            span=0.75, col=gray(c(0,0.5,0.7)),id.n=0)\n\n# this is just X vs. Y.  We can adjust for any specific variable comparisons we want to look at\nscatterplot(carat ~ price, data=diamonds, boxplots=FALSE, \n            span=0.75,id.n=0)\n\n# Numeric fields for sample scatterplot\norders.numeric <- orders.sample[c(\"price\",\"timeToDeliver\",\"accountAge\",\"customerAge\",\"numItemOrders\",\"numItemID\")]\n# (KT) I've been using this version for my scatterplot matrix\npanel.cor <-function(x,y,digits=3,prefix=\"\",cex.cor,...){ # gives you the ability to show correlation coefficients in the matrix\n  usr <- par(\"usr\")\n  on.exit(par(usr))\n  par(usr = c(0,1,0,1))\n  r <- abs(cor(x, y, use=\"complete.obs\"))\n  txt <- format(c(r,0.123456789),digits=digits)[1]\n  txt <- paste(prefix,txt,sep=\"\")\n  if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)\n  cex.col <- \"black\"\n  if(r > 0.4) cex.col=\"blue\" # this highlights large values- if not needed you can remove this line and the one above, as well as the col= below\n  text(0.5,0.5,txt,cex = cex.cor*(1+r)/2,col=cex.col)\n} # Modified from R Graphics Cookbook\npanel.density <-function(x,...){ # allows you to show density on the diagonal\n  usr <- par(\"usr\")\n  on.exit(par(usr))\n  dd <- density(x, na.rm=TRUE)\n  xr = range(dd$x)\n  yr = range(dd$y)\n  par(usr = c(min(xr), max(xr), min(yr), max(yr) * 1.5))\n  plot.xy(xy.coords(dd$x, dd$y), type = \"l\", col = \"black\", \n          ...)\n  box(col = \"lightgray\")\n} # Modified from corrgram package version of panel.density\n\npairs(Orders.numeric,pch=\".\",diag.panel=panel.density,lower.panel=panel.smooth,upper.panel=panel.cor,main=\"Scatterplot Matrix\") \n# pch = \".\" uses dots instead of circles for points. Leave out if circles are what you want.\n\n# (KT) Alternate using corrgram package\ncorrgram(orders.numeric,main=\"Correlations\",lower.panel=panel.ellipse,diag.panel=panel.density)\n\n#------------------------------------------#\n# Conditioned XY Plots - to look in panels #\n#------------------------------------------#\n# this was a handy XYplot tool to look at the relationship between 2 variables, conditioned by other variables\n# this was borrowed from our diamonds data set program\n# showing the relationship between price and carat, while conditioning\n# on cut and channel provides a convenient view of the diamonds data\n# in addition, we jitter to show all points in the data frame\nxyplot(jitter(sqrtprice) ~ jitter(carat) | channel + cut, \n       data = diamonds,\n       aspect = 1, \n       layout = c(3, 2),\n       strip=function(...) strip.default(..., style=1),\n       xlab = \"Size or Weight of Diamond (carats)\", \n       ylab = \"Price\")\n\n\n#------------------------------------------------#\n# to run some Weka algorithms - good for EDA too #\n#------------------------------------------------#\n\n# May need to add pruning rules for j48 and JRip #\n\n# to run j48 in RWeka\nreturns_j48 <- J48(returnShipment~., data = train)\nreturns_j48\nsummary(returns_j48)\n\n# to add a 10-folds cross-validation (does it help?)\neval_j48 <- evaluate_Weka_classifier(returns_j48, numFolds = 10, complexity = FALSE, \n                                     seed = 1, class = TRUE)\neval_j48\n\n# To run JRip - Recall this shows rules - will not plot a tree\nreturns_JRip <- JRip(class ~., data = orders.train)\nreturns_JRip\nsummary(returns_JRip)\n",
    "created" : 1398648870266.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1407140796",
    "id" : "55D209ED",
    "lastKnownWriteTime" : 1399158467,
    "path" : "~/GitHub/CAPSTONE/Analysis.R",
    "project_path" : "Analysis.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}